{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv('./datasets/reddit_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reddit.drop('is_news', axis=1)\n",
    "y = reddit['is_news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled = open('mnb_tfidf_gs_pkl', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = pickle.load(pickled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 0.1,\n",
       " 'tfidf__max_df': 0.75,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.75, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', binary=False,\n",
    "                                 decode_error='strict',\n",
    "                                 encoding='utf-8', input='content',\n",
    "                                 lowercase=True, max_df=0.75, max_features=None,\n",
    "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
    "                                 preprocessor=None, smooth_idf=True,\n",
    "                                 stop_words=None, strip_accents=None,\n",
    "                                 sublinear_tf=False,\n",
    "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                                 tokenizer=None, use_idf=True,\n",
    "                                 vocabulary=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = tfidf.fit_transform(X_train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.SparseDataFrame(train_raw, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000 000</th>\n",
       "      <th>000 americans</th>\n",
       "      <th>000 baby</th>\n",
       "      <th>000 brown</th>\n",
       "      <th>000 burning</th>\n",
       "      <th>000 cases</th>\n",
       "      <th>000 child</th>\n",
       "      <th>000 children</th>\n",
       "      <th>000 criminal</th>\n",
       "      <th>...</th>\n",
       "      <th>zoologists</th>\n",
       "      <th>zoologists thrilled</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuckerberg has</th>\n",
       "      <th>zuckerberg lost</th>\n",
       "      <th>zuckerberg of</th>\n",
       "      <th>zuckerberg prepares</th>\n",
       "      <th>zuckerberg touts</th>\n",
       "      <th>zumtrel</th>\n",
       "      <th>zumtrel flooby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  000 000  000 americans  000 baby  000 brown  000 burning  000 cases  \\\n",
       "0  0.0      0.0            0.0       0.0        0.0          0.0        0.0   \n",
       "1  0.0      0.0            0.0       0.0        0.0          0.0        0.0   \n",
       "2  0.0      0.0            0.0       0.0        0.0          0.0        0.0   \n",
       "3  0.0      0.0            0.0       0.0        0.0          0.0        0.0   \n",
       "4  0.0      0.0            0.0       0.0        0.0          0.0        0.0   \n",
       "\n",
       "   000 child  000 children  000 criminal  ...  zoologists  \\\n",
       "0        0.0           0.0           0.0  ...         0.0   \n",
       "1        0.0           0.0           0.0  ...         0.0   \n",
       "2        0.0           0.0           0.0  ...         0.0   \n",
       "3        0.0           0.0           0.0  ...         0.0   \n",
       "4        0.0           0.0           0.0  ...         0.0   \n",
       "\n",
       "   zoologists thrilled  zuckerberg  zuckerberg has  zuckerberg lost  \\\n",
       "0                  0.0         0.0             0.0              0.0   \n",
       "1                  0.0         0.0             0.0              0.0   \n",
       "2                  0.0         0.0             0.0              0.0   \n",
       "3                  0.0         0.0             0.0              0.0   \n",
       "4                  0.0         0.0             0.0              0.0   \n",
       "\n",
       "   zuckerberg of  zuckerberg prepares  zuckerberg touts  zumtrel  \\\n",
       "0            0.0                  0.0               0.0      0.0   \n",
       "1            0.0                  0.0               0.0      0.0   \n",
       "2            0.0                  0.0               0.0      0.0   \n",
       "3            0.0                  0.0               0.0      0.0   \n",
       "4            0.0                  0.0               0.0      0.0   \n",
       "\n",
       "   zumtrel flooby  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 29416 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw = tfidf.transform(X_test['text'])\n",
    "test_df = pd.SparseDataFrame(test_raw, columns=tfidf.get_feature_names())\n",
    "test_df.fillna(0, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492849284928493"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29416"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.transpose(mnb.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importance = pd.DataFrame(np.transpose(mnb.coef_), train_df.columns, columns=['is_news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zumtrel flooby</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectacular</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spectacular news</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speculate</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in rpg</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in rowboat</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in road</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special meetings</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in ringing</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in rich</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in revealing</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in retrospect</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speculate about</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech is</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in real</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in ring</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech oprah</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in same</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special flights</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in solidarity</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in solely</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in solar</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in smaller</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spazio sells</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in sioux</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special guest</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speak to</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speakers white</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in septic</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in search</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be extra</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be fatal</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be fine</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warnings</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be fragments</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warning the</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be fucking</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be fun</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be given</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warned you</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be last</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warning signs</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be kept</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be just</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be judge</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be defined</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be interested</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be here</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be haunted</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be happy</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be had</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be good</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be going</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be heroin</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be cute</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be considered</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be christian</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bats to</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bats</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batman</th>\n",
       "      <td>-11.15327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   is_news\n",
       "zumtrel flooby   -11.15327\n",
       "spectacular      -11.15327\n",
       "spectacular news -11.15327\n",
       "speculate        -11.15327\n",
       "in rpg           -11.15327\n",
       "in rowboat       -11.15327\n",
       "in road          -11.15327\n",
       "special meetings -11.15327\n",
       "in ringing       -11.15327\n",
       "in rich          -11.15327\n",
       "in revealing     -11.15327\n",
       "in retrospect    -11.15327\n",
       "speculate about  -11.15327\n",
       "speech is        -11.15327\n",
       "in real          -11.15327\n",
       "in ring          -11.15327\n",
       "speech oprah     -11.15327\n",
       "in same          -11.15327\n",
       "special flights  -11.15327\n",
       "in solidarity    -11.15327\n",
       "in solely        -11.15327\n",
       "in solar         -11.15327\n",
       "in smaller       -11.15327\n",
       "spazio sells     -11.15327\n",
       "in sioux         -11.15327\n",
       "special guest    -11.15327\n",
       "speak to         -11.15327\n",
       "speakers white   -11.15327\n",
       "in septic        -11.15327\n",
       "in search        -11.15327\n",
       "...                    ...\n",
       "be extra         -11.15327\n",
       "be fatal         -11.15327\n",
       "be fine          -11.15327\n",
       "warnings         -11.15327\n",
       "be fragments     -11.15327\n",
       "warning the      -11.15327\n",
       "be fucking       -11.15327\n",
       "be fun           -11.15327\n",
       "be given         -11.15327\n",
       "warned you       -11.15327\n",
       "be last          -11.15327\n",
       "warning signs    -11.15327\n",
       "be kept          -11.15327\n",
       "be just          -11.15327\n",
       "be judge         -11.15327\n",
       "be defined       -11.15327\n",
       "be interested    -11.15327\n",
       "be here          -11.15327\n",
       "be haunted       -11.15327\n",
       "be happy         -11.15327\n",
       "be had           -11.15327\n",
       "be good          -11.15327\n",
       "be going         -11.15327\n",
       "be heroin        -11.15327\n",
       "be cute          -11.15327\n",
       "be considered    -11.15327\n",
       "be christian     -11.15327\n",
       "bats to          -11.15327\n",
       "bats             -11.15327\n",
       "batman           -11.15327\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance.sort_values(by='is_news', ascending=True).head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.keys of zumtrel flooby     -11.153270\n",
       "spectacular        -11.153270\n",
       "spectacular news   -11.153270\n",
       "speculate          -11.153270\n",
       "in rpg             -11.153270\n",
       "in rowboat         -11.153270\n",
       "in road            -11.153270\n",
       "special meetings   -11.153270\n",
       "in ringing         -11.153270\n",
       "in rich            -11.153270\n",
       "in revealing       -11.153270\n",
       "in retrospect      -11.153270\n",
       "speculate about    -11.153270\n",
       "speech is          -11.153270\n",
       "in real            -11.153270\n",
       "in ring            -11.153270\n",
       "speech oprah       -11.153270\n",
       "in same            -11.153270\n",
       "special flights    -11.153270\n",
       "in solidarity      -11.153270\n",
       "in solely          -11.153270\n",
       "in solar           -11.153270\n",
       "in smaller         -11.153270\n",
       "spazio sells       -11.153270\n",
       "in sioux           -11.153270\n",
       "special guest      -11.153270\n",
       "speak to           -11.153270\n",
       "speakers white     -11.153270\n",
       "in septic          -11.153270\n",
       "in search          -11.153270\n",
       "                      ...    \n",
       "marijuana           -7.507146\n",
       "woman               -7.405757\n",
       "trump               -7.391846\n",
       "was                 -7.361181\n",
       "year old            -7.303763\n",
       "as                  -7.283432\n",
       "old                 -7.257595\n",
       "years               -7.227169\n",
       "over                -7.205112\n",
       "has                 -7.185172\n",
       "arrested            -7.162855\n",
       "us                  -7.096928\n",
       "year                -7.092297\n",
       "is                  -7.051958\n",
       "says                -7.014682\n",
       "who                 -6.999005\n",
       "with                -6.976896\n",
       "by                  -6.899131\n",
       "man                 -6.889705\n",
       "police              -6.867603\n",
       "from                -6.815936\n",
       "at                  -6.762239\n",
       "and                 -6.656814\n",
       "on                  -6.604630\n",
       "after               -6.586877\n",
       "the                 -6.460700\n",
       "of                  -6.303059\n",
       "for                 -6.269362\n",
       "to                  -5.938948\n",
       "in                  -5.826616\n",
       "Name: is_news, Length: 29416, dtype: float64>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance['is_news'].sort_values(ascending=True).keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mnb.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(cm, columns=['pred r/TheOnion', 'pred r/news'], index=['actual r/TheOnion', 'actual r/news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred r/TheOnion</th>\n",
       "      <th>pred r/news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual r/TheOnion</th>\n",
       "      <td>475</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual r/news</th>\n",
       "      <td>78</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred r/TheOnion  pred r/news\n",
       "actual r/TheOnion              475           59\n",
       "actual r/news                   78          297"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = cvec.fit_transform(X_train['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.SparseDataFrame(train_raw, columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_raw, columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to            868\n",
       "of            628\n",
       "in            537\n",
       "the           437\n",
       "for           370\n",
       "on            258\n",
       "after         213\n",
       "and           210\n",
       "with          192\n",
       "man           160\n",
       "that          160\n",
       "at            158\n",
       "is            154\n",
       "by            153\n",
       "he            152\n",
       "from          142\n",
       "who           141\n",
       "has           126\n",
       "it            126\n",
       "new           122\n",
       "this          120\n",
       "as            108\n",
       "his           104\n",
       "trump         103\n",
       "be            101\n",
       "out            90\n",
       "just           88\n",
       "year           82\n",
       "have           80\n",
       "up             76\n",
       "             ... \n",
       "migrating       1\n",
       "milano          1\n",
       "miles           1\n",
       "miley           1\n",
       "milkshake       1\n",
       "mill            1\n",
       "millwall        1\n",
       "milo            1\n",
       "minaj           1\n",
       "mets            1\n",
       "metroid         1\n",
       "metric          1\n",
       "merit           1\n",
       "melting         1\n",
       "membership      1\n",
       "meme            1\n",
       "memorable       1\n",
       "memorials       1\n",
       "memories        1\n",
       "mercifully      1\n",
       "merkel          1\n",
       "method          1\n",
       "mesa            1\n",
       "mess            1\n",
       "messages        1\n",
       "messam          1\n",
       "messing         1\n",
       "metal           1\n",
       "meteors         1\n",
       "kal             1\n",
       "Length: 7406, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
